{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Проект\n",
    "Данный проект нацелен на анализ вакансий от работодателей финансового сектора на сайте hh.ru\n",
    "С целью сбора данных был написан специальный парсер (parser.ipynb)\n",
    "В данном ноутбуке используется спарсенная заранее таблица с данными.\n",
    "\n",
    "Предполагается сначала предварительно обработать датасет, затем уже описать содержащиеся внутри данные в процессе визуализации."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Импорт библиотек"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T19:01:18.282919500Z",
     "start_time": "2023-05-15T19:01:18.170389900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Чтение датасета и предварительная обработка\n",
    "Посмотрим как выглядят данные, удалим ненужные колонки, заполним NaN значения, преобразуем данные.\n",
    "Начнём с чтения датасета. Так же посмотрим как он вообще выглядит."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'fin-sec_15_05_2023.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[427], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfin-sec_15_05_2023.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m df\u001B[38;5;241m.\u001B[39mhead()\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\JetBrains\\DataSpell2023.1\\projects\\workspace\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m    899\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    900\u001B[0m     dialect,\n\u001B[0;32m    901\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    908\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m    909\u001B[0m )\n\u001B[0;32m    910\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 912\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\JetBrains\\DataSpell2023.1\\projects\\workspace\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    574\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    576\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 577\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    579\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    580\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\JetBrains\\DataSpell2023.1\\projects\\workspace\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1404\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1406\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1407\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\JetBrains\\DataSpell2023.1\\projects\\workspace\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1659\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1660\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1661\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1662\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1663\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1664\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1665\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1666\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1667\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1668\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1669\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1670\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1671\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1672\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\JetBrains\\DataSpell2023.1\\projects\\workspace\\venv\\Lib\\site-packages\\pandas\\io\\common.py:859\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    854\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    855\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    856\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    857\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    858\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 859\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[0;32m    860\u001B[0m             handle,\n\u001B[0;32m    861\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[0;32m    862\u001B[0m             encoding\u001B[38;5;241m=\u001B[39mioargs\u001B[38;5;241m.\u001B[39mencoding,\n\u001B[0;32m    863\u001B[0m             errors\u001B[38;5;241m=\u001B[39merrors,\n\u001B[0;32m    864\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    865\u001B[0m         )\n\u001B[0;32m    866\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    867\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    868\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'fin-sec_15_05_2023.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('fin-sec_15_05_2023.csv')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T19:01:18.360237700Z",
     "start_time": "2023-05-15T19:01:18.171894300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Давайте посмотрим что вообще находится внутри датасета."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T19:01:18.307225100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Как можно заметить на данном этапе:\n",
    "Колонки department, insider_interview содержат слишком мало данных для работы с ними.\n",
    "\n",
    "Колонки response_url, sort_point_distance и adv_response_url, contacts, schedule пустые.\n",
    "\n",
    "Среди данных, которые нам не нужны имеем следующее:\n",
    "Unnamed: 0 - всё равно, что индекс.\n",
    "Premium - не несёт практической пользы для анализа.\n",
    "Name - необъективная информация.\n",
    "Area - у нас и так только один регион.\n",
    "Type - не несёт практической пользы для анализа.\n",
    "Address - не несёт практической пользы для анализа.\n",
    "Published_at - не несёт практической пользы для анализа.\n",
    "Created_at - не несёт практической пользы для анализа.\n",
    "Archived - не несёт практической пользы для анализа.\n",
    "Apply_alternate_url - не несёт практической пользы для анализа.\n",
    "Url - не несёт практической пользы для анализа.\n",
    "Alternate_url - не несёт практической пользы для анализа.\n",
    "Relations - не несёт практической пользы для анализа.\n",
    "Employer - не несёт практической пользы для анализа.\n",
    "Snippet - необъективная информация.\n",
    "Working_days - неполные и/или нерелевантные данные.\n",
    "Working_time_intervals - неполные и/или нерелевантные данные.\n",
    "Working_time_modes - неполные и/или нерелевантные данные.\n",
    "\n",
    "Соберём все выше указанные колонки в список и удалим."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_for_deletion = ['department', 'insider_interview', 'response_url', 'sort_point_distance', 'adv_response_url', 'contacts', 'schedule', 'Unnamed: 0', 'premium', 'name', 'area', 'type', 'address', 'published_at', 'created_at', 'archived', 'apply_alternate_url', 'url', 'alternate_url', 'relations', 'employer', 'snippet', 'working_days', 'working_time_intervals', 'working_time_modes']\n",
    "\n",
    "df.drop(list_for_deletion, axis=1, inplace=True)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T19:01:18.308225800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "В данном случае id вакансии уникальное значение, потому мы можем сделать её индексом."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.set_index('id', inplace=True, drop=True)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T19:01:18.309225500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Важно заметить, что колонки salary, professional_role, experience и employment представлены в виде словарей.\n",
    "Эти данные необходимо вытащить из словаря."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Зарплата\n",
    "df[\"salary\"] =  df[\"salary\"].map(lambda d : ast.literal_eval(d))\n",
    "df_buffer = df.join(pd.DataFrame(df[\"salary\"].to_dict()).T)\n",
    "df_buffer = df_buffer.fillna(value=np.nan)  # Не у всех вакансий есть минимальная и максимальная зарплата"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T19:01:18.310225600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df_buffer[['has_test', 'response_letter_required', 'accept_temporary', 'professional_roles', 'accept_incomplete_resumes', 'experience', 'employment', 'from', 'to', 'currency', 'gross']]\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T19:01:18.311226300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Поскольку мы не можем заполнить отсутствующие значения from и to без нарушения логики датасета с помощью среднего или медианы (когда у вакансий минимальная может быть выше максимальной и т.п.), то заполним эти две колонки в одну следующим образом:\n",
    "Если указана только минимальная, то устанавливаем её и как максимальную.\n",
    "Если указана только максимальная, то устанавливаем её и как минимальную."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['to'] = df['to'].fillna(df['from'])\n",
    "df['from'] = df['from'].fillna(df['to'])\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T19:01:18.312225900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Профессия\n",
    "df['professional_roles'] =  df['professional_roles'].map(lambda d : ast.literal_eval(d))\n",
    "\n",
    "dict_buff = df['professional_roles'].to_dict()\n",
    "for key in dict_buff:\n",
    "    dict_buff[key] = dict(name = dict_buff[key][0]['name'])\n",
    "\n",
    "df_buffer = df.join(pd.DataFrame(dict_buff).T)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T19:01:18.313226200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df_buffer[['name', 'from', 'to', 'currency', 'gross', 'has_test', 'response_letter_required', 'accept_temporary', 'accept_incomplete_resumes', 'experience', 'employment']]\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T19:01:18.314227200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Опыт\n",
    "df['experience'] =  df['experience'].map(lambda d : ast.literal_eval(d))\n",
    "\n",
    "dict_buff = df['experience'].to_dict()\n",
    "for key in dict_buff:\n",
    "    dict_buff[key] = dict(exp_buff = dict_buff[key]['name'])\n",
    "\n",
    "df_buffer = df.join(pd.DataFrame(dict_buff).T)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T19:01:18.315226900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df_buffer[['name', 'from', 'to', 'currency', 'gross', 'has_test', 'response_letter_required', 'accept_temporary', 'accept_incomplete_resumes', 'exp_buff', 'employment']]\n",
    "df.rename(columns={'exp_buff': 'experience'}, inplace=True)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T19:01:18.316227700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Тип занятости\n",
    "df['employment'] =  df['employment'].map(lambda d : ast.literal_eval(d))\n",
    "\n",
    "dict_buff = df['employment'].to_dict()\n",
    "for key in dict_buff:\n",
    "    dict_buff[key] = dict(emp_buff = dict_buff[key]['name'])\n",
    "\n",
    "df_buffer = df.join(pd.DataFrame(dict_buff).T)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T19:01:18.318227500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df_buffer[['name', 'from', 'to', 'currency', 'gross', 'has_test', 'response_letter_required', 'accept_temporary', 'accept_incomplete_resumes', 'experience', 'emp_buff']]\n",
    "df.rename(columns={'emp_buff': 'employment'}, inplace=True)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T19:01:18.319228Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Последнее, что стоит сделать закодировать все True и False значения в числовой вариант 1 и 0, для простоты работы в будущем."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['gross'] = np.where(df['gross'] == False, 0, 1)\n",
    "df['has_test'] = np.where(df['has_test'] == False, 0, 1)\n",
    "df['response_letter_required'] = np.where(df['response_letter_required'] == False, 0, 1)\n",
    "df['accept_temporary'] = np.where(df['accept_temporary'] == False, 0, 1)\n",
    "df['accept_incomplete_resumes'] = np.where(df['accept_incomplete_resumes'] == False, 0, 1)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T19:01:18.320228500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "На этом обработка спарсенного датасета окончена. Можно переходить к визуализации."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Визуализация\n",
    "\n",
    "На этом этапе мы рассмотрим значение каждой колонки датасета, а так же посмотрим на интересные закономерности, которые можно в нём найти."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### **Начнём с описания колонок датасета:**\n",
    "**index** — уникальный id вакансии на hh.ru\n",
    "**name** — профессия вакансии\n",
    "**from** — минимальная зарплата\n",
    "**to** — максимальная зарплата\n",
    "**currency** — валюта выплаты\n",
    "**gross** — указанна ли сумма до удержания налогов\n",
    "**has_test** — нужно ли пройти тест перед отправкой резюме\n",
    "**response_letter_required** — нужно ли сопроводительное письмо\n",
    "**accept_temporary** — временная или постоянная работа\n",
    "**accept_incomplete_resumes** — принимается ли неполное резюме\n",
    "**experience** — требуемый опыт\n",
    "**employment** — тип занятости"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Общий осмотр данных по колонкам в датасете\n",
    "\n",
    "Кажется интересным начать с того, чтобы взглянуть на соотношение валют в нашем датасете."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "currencies = df['currency'].value_counts()\n",
    "currencies"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T19:01:18.321228200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Результат уже говорит о многом, однако всё же можно визуализировать этот момент."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keys = ['RUB', 'USD']\n",
    "data = [1986/2000, 14/2000]\n",
    "\n",
    "palette_color = sb.color_palette('bright')\n",
    "plt.pie(data, labels=keys, colors=palette_color, autopct='%.0f%%')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T19:01:18.322228900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Раз у нас всего две валюты, то мы можем их закодировать, для простоты работы в будущем.\n",
    "Пускай RUR будет равен 1, а USD 0."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['currency'] = np.where(df['currency'] == 'RUR', 1, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T19:01:18.323229300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь лучше взглянуть на что-то, что может оказаться поинтереснее, на пример распределение по профессиям."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "professions = df['name'].value_counts()\n",
    "professions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T19:01:18.323229300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "У нас вышло 130 профессий.\n",
    "Можем визуализировать первые 10 из них, а все остальные загнать в \"Другое\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "professions.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T19:01:18.324228700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keys = professions.head(10).keys()\n",
    "data = [459/2000, 1105/2000, 91/2000, 91/2000, 66/2000, 52/2000, 50/2000, 44/2000, 42/2000, 36/2000]\n",
    "\n",
    "palette_color = sb.color_palette('bright')\n",
    "plt.pie(data, labels=keys, colors=palette_color, autopct='%.0f%%')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T19:01:18.325229600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "О чём из подобной графики можно судить?\n",
    "В первую очередь о том, что самая востребованная профессия среди работодателей в финансовом секторе это менеджер по продажам. Говорить о причинах такой тенденции сложно, поскольку причины могут быть самыми различными, от большой текучки в сфере, до растущей потребности в более прямой продаже продукта на фоне растущей конкуренции.\n",
    "\n",
    "Так же интересным элементом выделяется и разнообразие среди профессий. Более половины всех вакансий в выборке, это вакансии, необходимая для которых профессия встречается реже, чем в 36 случаях."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь же, прежде чем окончательно перейти к выявлению закономерностей между данными, можем взглянуть на требование написания сопроводительного письма к резюме."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "letter = df['response_letter_required'].value_counts()\n",
    "letter"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T19:01:18.325229600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Результат, так же как и в случае с валютами, вышел малоинтересным.\n",
    "Но всё же стоит визуализировать."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keys = ['Требуется письмо', 'Не требуется письмо']\n",
    "data = [1964/2000, 36/2000]\n",
    "\n",
    "palette_color = sb.color_palette('bright')\n",
    "plt.pie(data, labels=keys, colors=palette_color, autopct='%.0f%%')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T19:01:18.326229500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Взаимосвязь между данными"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
